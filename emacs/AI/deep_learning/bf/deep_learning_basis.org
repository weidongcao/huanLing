* 深度学习概述
** 感知器网络理解以及S型神经元
   针对感知器网络的这种很难学习的问题,引入S型神经元来代替感知器,从而解决这个问题
   从感知器模型中,我们可以单个神经元的计算过程看成下列两个步骤:
   1. 先计算权重W和输入值x以及偏置项b之间的线性结果值z: z = wx + b
   2. 然后对结果值z进行一个数据的sign函数(变种)转换,得到一个离散的0/1值:y = int((sign(z) + 1)/2)
   
   在S型神经元中,和感知器神经元的区别在于:
   对于结果值z的转换,采用的不是sign函数进行转换,是采用平滑类型的函数进行转换,让输出的结果值y最终是一个连续的,S型神经元转指使用的是Sigmod函数
** 激活函数
   激活函数的主要作用是提供网络的非线性建模能力,如果没有激活函数,那么该网络仅能够表达线性映射,此时即便有再多的隐藏层,其整个网络跟单层神经网络也是等价的.因此也可以认为只有加入了激活函数之后,深度神经网络才具备了分层的非线性映射学习能力.
   激活函数的主要特性是:
   - 可徽性
   - 单调性
   - 输出值的范围

   常用的激活函数:
   - sign函数
   - Sigmod函数
   - tanh函数
   - RelU函数
   - P-RelU函数
   - Leaky-RelU函数
   - ELU函数
   - Maxout函数
