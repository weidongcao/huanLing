* 决策回归树
** 决策树的剪枝
 - 决策树的剪枝是决策树算法中最基本,最有用的一种优化方案,主要分为两大类:
   - 前置剪枝:在构建决策树的过程中,提前停止.结果是决策树一般比较小,实践证明这种策略无法得到比较好的结果.
   - 后置剪枝:在决策树构建好后,然后再开始裁剪,一般使用两种方式:
     - 1) 用单一叶子节点代替整个子树,叶节点的分类采用子树中最多主要的分类;
     - 2) 将一个子树完全零花另外一棵子树;后置剪枝的主要问题是计算效率问题,存在一定的浪费情况.
 - 后剪枝总体思路(交叉验证)
   - 由完全树T0开始,剪枝部分节点得到T1,在此剪枝得到T2...直到仅剩树根的树Tk
   - 在验证数据集上对这k+1个树进行评价,选择最优树Ta(损失函数最小的树)

** 决策树剪枝过程
 - 对于给定的决策树T0
   - 计算所有内部非叶子节点的剪枝系数
   - 查找最小剪枝系数的节点,将其子节点进行删除操作,进行剪枝得到决策树Tk;如果存在多个最小剪枝系数节点,选择包含数据项最多的节点进行剪枝操作.
   - 重复上述操作,直到产生的剪枝决策树Tk只有一个节点
   - 得到决策树T0, T1, T2 ... Tk
   - 使用验证样本集选择最优子树Ta
 - 使用验证集选择最优子树的标准,可以使用原始损失函数来考虑:
