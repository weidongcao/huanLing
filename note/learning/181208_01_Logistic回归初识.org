* Logistic回归初识
** Odds
*定义*: 比值比or优势比,用来衡量特征当中分类之间关联的一种方式.指的是该事件发生的概率与该事件不发生的概率的比值. p/1-p

由此引出一个新的函数 --> Logit函数:
logit(p) = log(p/1-p) = \theta^T X

logit函数的取值范围为+无穷到-无穷

logit函数是人为定义的.在坐标轴上画出来是这样的:
#+CAPTION: This is the caption for the next figure link (or table)
#+LABEL: fig:SED-HR4049
[[./logistic/logit_function.png][logit_function]]


为什么logit函数 = \theta^T * X
\theta^T表示矩阵的转置
我们假设logit函数符合某种线性关系,也就是说和我们的特征之间呈现某种线性关系,注意,这是我们人为定义的.

*为什么可以这么人为定义呢?*
机器学习中好多算法都是基于某种人为定义的假设,然后基于这种假设进行层层的推导,最终得到某种模型,然后用数据验证我们的假设是否理想(准确率有多高),不理想的话再换一种模型(换一种假设)

X轴为P的取值,Y轴为Y的取值,如果呈现某种线性关系的话,所以本质上也是X的取值,只不过乘上某个系数,或者再加上某个常数.
所以我们可以把原来的坐标轴转换一下:
[[file:Logistic/p_x.png][p_x坐标轴]]
旋转的本质其实就是反函数,本来是P和Y之间的关系,现在变成了Y和P之间的关系,而Y = Q^T X
于是我们可以得到一个P关于X的函数
于是原来的logitb函数就变成了:
[[file:Logistic/reverse_logit_function.png][reverse_logit_function]]
这个函数的名称叫sigimoid函数,这个英文的意思就是S形(函数),所以说为什么都说身材好叫有S形曲线,一方面确实是.
我们可以发现它是一个关于(0, 0.5)对称的奇函数,
于是有:
$$ f(x) + f(-x) = 1 $$
是不是一个很好的性质?

Logit函数为:
$$ logit(p)  = y = \ln \frac{p}{1-p} =\theta^{T}X $$

这个是Y关于P的函数,那么如何转成P关于X的函数呢?
即: $P = f(x)$
我们知道:
$$
y = \ln \frac{p}{1-p}
y = \theta^{T}X
$$
于是有:
$$ 
\ln \frac{p}{1-p} = \theta^{T}X
$$
两边同时取$e$,于是有:
$$ 
\frac{p}{1-p} = e^{\theta^TX}

p &= (1 - p)e^{\theta^{T}X}
&=e^{\theta^{T}X} - p \dot e^{\theta^{T}X}
(1 + e^{\theta^{T}X}) \dot p = e^\{\theta^{T}X}

p &= \frac{e^{\theta^{T}X}}{1 + e^{\theta^{T}X}}
 &= \frac{1}{1 + e^{-\theta^{T}X}}
$$
于是我们的sigmoid函数就出来了:
$$p = h_{\theta}(x) = g(\theta^T x) = \frac{1}{1 + e^{-\theta^{T}x}}$$
让我们再回到当初,
当初我们为什么要求解这个sigmoid函数呢?
一开始的时候我们有logist函数,通过这个函数我们可以输入一个p然后得到一个y,但是这没什么鸟用
于是我们假定x与Y之间存在某种线性关系,通过X与Y和Y与P之间的关系,我们得到sigmoid函数,即输入一个x(特征值)得到一个p(概率),这个就很有用了.
那么当初的logit函数为什么要加个$\ln$呢?
OK,这就是sigmoid函数的核心:推导出来的sigmoid函数将原有函数的取值范围映射到了0和1之间,即:
$$ p ~ (0, 1) $$
OK,它是不是与概率的取值范围是一致的呢?后面处处都会用到滴.

从X映射到P,其中缺少了一步:X先映射到Y,再映射到P,这样一个关系.我们想做的就是找到这样一种关系.
实际上最终就是:我们通过输入我们的数据,得到一个(0, 1)之间的这样一个值,注意,不包括0和1
找到这样一个映射关系之后,就可以对我们的数据进行分类了,

Y的本质是什么?
Y求的话正常应该X到某个数之间的映射肯定是映射成了一个连续的值,然后再把它映射到(0, 1)之间,
也就是说可能Y本质上就是一个类别(类别不是连续的,直接就是等于0,或者等于1,只有这两个值),而P则是取到不同Y值的概率.
为什么这么说呢?机器学习本质上就是概率论,任何时候都只能说取到0的概率是多少,取到1的概率是多少,而不敢绝对肯定.比如说一条数据有70%的可能性取到1,我们就可以认为它是取到1的.30%的可能性取到1,我们就认为它是取到0的.
为什么这么认为呢?一来有科学依据(概率论),二来方便将连续的函数值做二分类啊.

于是通过sigmoid函数,X映射到了一个连续的预测值$Y^*$,即P; 然后又通过这个$Y^*$映射到了$Y$真实值(只能是0或1)

$Y^*$怎么映射到$Y$呢?
太简单了,$f(x)$不是关于(0, 0.5)对称吗?将0.5作为一个阈值,概率大于0.5就是取到正例(即1),概率小于0.5就是取到负例(即0)
于是得到了Logistic回归的函数为:
y真实值为:
$$
y = 
\begin{cases}
0 \\
1 \\
\end{cases}
$$
y预测值为:
$$
\hat y = 
\begin{cases}
1, P(\hat y = 1) > p_阈 \\
0, P(\hat y = 0) \leq p_阈 \\
\end{cases}
$$

从而通过线性回归实现了分类的目的.
所以简单来讲,Logistic回归就是通过输入一个x值,得到一个概率,当这个概率大于某个阈值的时候,属于哪一类,小于某个阈值的时候属于哪一类.
为什么最好用线性回归做分类一定要慎重呢?
因为阈值不好确定,本例中的Logistic回归正好是$f(-x) + f(x) = 1$,$f(x)$是存在对称关系的,因此阈值是0.5很合理,但是如果不关于0.5对称呢?这个时候你所设定的阈值可能是盲目的,没有数学依据的.从而导致预测得不准确

怎么去求解一系列的$\theta$值呢?


怎么构造损失函数呢?
可以考虑下极大似然估计
在线性回归里$P(y|x)$符合正态分布:$y|x ~ N(\theta^Tx, \sigma^2)$
于是我们可以写出它的概率密度函数:
$$
\prod_{i=1}^{N} P(y|x) = \prod P(y^{1}y^{2}y^{3} \cdots y^{m} | x_1 \cdot \theta)
$$
于是我们可以知道不同的观测值之间是独立同分布的.

我这里还能用最小二乘法去求吗？由于Y值不是连续的因此无法用最小二乘法区，构造。那那么我们是否可以先求他的损失函数呢？预测值和真实值之间叉的平方合并不太能够预测或者使我的模型达到更准确。

我们可以先不考虑怎样去求Q的值，而思考怎样去构造损失函数。首先我们还可以考虑一下，用我们的极大似然估计。

在线性回归里Y在给定x的情况下，符合什么分布？



Y在给定x的情况下，符合正态分布，它是由随机误差项推导出来的。

通过Y服从这样一个概率分布，我们可以写出它的概率密度函数。我们可以通过一个连乘，从而得到，全概率密度函数。

通过这样一个公式，我们还可以推导出来，Y之间是，相互独立的，从而我们才可以得到。得到，条件概率公式。



在给定x和c套的情况下，外服从泊松分布。服从伯努利分布。

它是由多个伯努利分布连续实验得到的结果。



我没让我去正例，要么取负例，正立的概率是批复率的概率是一减p。


